# This file is managed by Puppet

# SINGULARITY.CONF
# This is the global configuration file for Singularity. This file controls
# what the container is allowed to do on a particular host, and as a result
# this file must be owned by root.

# ALLOW SETUID: [BOOL]
# DEFAULT: yes
# Should we allow users to utilize the setuid program flow within Singularity?
# note1: This is the default mode, and to utilize all features, this option
# must be enabled.  For example, without this option loop mounts of image 
# files will not work; only sandbox image directories, which do not need loop
# mounts, will work (subject to note 2).
# note2: If this option is disabled, it will rely on unprivileged user
# namespaces which have not been integrated equally between different Linux
# distributions.
<% if scope.lookupvar('::singularity::allow_setuid') -%>
allow setuid = yes
<% else -%>
allow setuid = no
<% end -%>

# MAX LOOP DEVICES: [INT]
# DEFAULT: 256
# Set the maximum number of loop devices that Singularity should ever attempt
# to utilize.
max loop devices = <%= scope.lookupvar('::singularity::max_loop_devices') %>

# ALLOW PID NS: [BOOL]
# DEFAULT: yes
# Should we allow users to request the PID namespace? Note that for some HPC
# resources, the PID namespace may confuse the resource manager and break how
# some MPI implementations utilize shared memory. (note, on some older
# systems, the PID namespace is always used)
<% if scope.lookupvar('::singularity::allow_pid_ns') -%>
allow pid ns = yes
<% else -%>
allow pid ns = no
<% end -%>

# CONFIG PASSWD: [BOOL]
# DEFAULT: yes
# If /etc/passwd exists within the container, this will automatically append
# an entry for the calling user.
<% if scope.lookupvar('::singularity::config_passwd') -%>
config passwd = yes
<% else -%>
config passwd = no
<% end -%>

# CONFIG GROUP: [BOOL]
# DEFAULT: yes
# If /etc/group exists within the container, this will automatically append
# group entries for the calling user.
<% if scope.lookupvar('::singularity::config_group') -%>
config group = yes
<% else -%>
config group = no
<% end -%>

# CONFIG RESOLV_CONF: [BOOL]
# DEFAULT: yes
# If there is a bind point within the container, use the host's
# /etc/resolv.conf.
<% if scope.lookupvar('::singularity::config_resolv_conf') -%>
config resolv_conf = yes
<% else -%>
config resolv_conf = no
<% end -%>

# MOUNT PROC: [BOOL]
# DEFAULT: yes
# Should we automatically bind mount /proc within the container?
<% if scope.lookupvar('::singularity::mount_proc') -%>
mount proc = yes
<% else -%>
mount proc = no
<% end -%>

# MOUNT SYS: [BOOL]
# DEFAULT: yes
# Should we automatically bind mount /sys within the container?
<% if scope.lookupvar('::singularity::mount_sys') -%>
mount sys = yes
<% else -%>
mount sys = no
<% end -%>

# MOUNT DEV: [yes/no/minimal]
# DEFAULT: yes
# Should we automatically bind mount /dev within the container? If 'minimal'
# is chosen, then only 'null', 'zero', 'random', 'urandom', and 'shm' will
# be included (the same effect as the --contain options)
<% mount_dev = scope.lookupvar('::singularity::mount_dev') -%>
<% if !! mount_dev == mount_dev -%>
<% if mount_dev -%>
mount dev = yes
<% else -%>
mount dev = no
<% end -%>
<% else -%>
mount dev = <%= mount_dev %>
<% end -%>

# MOUNT DEVPTS: [BOOL]
# DEFAULT: yes
# Should we mount a new instance of devpts if there is a 'minimal'
# /dev, or -C is passed?  Note, this requires that your kernel was
# configured with CONFIG_DEVPTS_MULTIPLE_INSTANCES=y, or that you're
# running kernel 4.7 or newer.
<% if scope.lookupvar('::singularity::mount_devpts') -%>
mount devpts = yes
<% else -%>
mount devpts = no
<% end -%>

# MOUNT HOME: [BOOL]
# DEFAULT: yes
# Should we automatically determine the calling user's home directory and
# attempt to mount it's base path into the container? If the --contain option
# is used, the home directory will be created within the session directory or
# can be overridden with the SINGULARITY_HOME or SINGULARITY_WORKDIR
# environment variables (or their corresponding command line options).
<% if scope.lookupvar('::singularity::mount_home') -%>
mount home = yes
<% else -%>
mount home = no
<% end -%>

# MOUNT TMP: [BOOL]
# DEFAULT: yes
# Should we automatically bind mount /tmp and /var/tmp into the container? If
# the --contain option is used, both tmp locations will be created in the
# session directory or can be specified via the  SINGULARITY_WORKDIR
# environment variable (or the --workingdir command line option).
<% if scope.lookupvar('::singularity::mount_tmp') -%>
mount tmp = yes
<% else -%>
mount tmp = no
<% end -%>

# MOUNT HOSTFS: [BOOL]
# DEFAULT: no
# Probe for all mounted file systems that are mounted on the host, and bind
# those into the container?
<% if scope.lookupvar('::singularity::mount_hostfs') -%>
mount hostfs = yes
<% else -%>
mount hostfs = no
<% end -%>

# BIND PATH: [STRING]
# DEFAULT: Undefined
# Define a list of files/directories that should be made available from within
# the container. The file or directory must exist within the container on
# which to attach to. you can specify a different source and destination
# path (respectively) with a colon; otherwise source and dest are the same.
# NOTE: these are ignored if singularity is invoked with --contain.
#bind path = /etc/singularity/default-nsswitch.conf:/etc/nsswitch.conf
#bind path = /opt
#bind path = /scratch
<% bind_path = scope.lookupvar('::singularity::bind_path') -%>
<% if bind_path.is_a?(Array) -%>
<% bind_path.each do |bp| -%>
<% if bp =~ /^\/([^\/\0]+\/*)+$/ -%>
bind path = <%= bp %>
<% elsif bp.is_a?(Hash) -%>
bind path = <%= bp['source'] %>:<%= bp['destination'] %>
<% end -%>
<% end -%>
<% end -%>

# USER BIND CONTROL: [BOOL]
# DEFAULT: yes
# Allow users to influence and/or define bind points at runtime? This will allow
# users to specify bind points, scratch and tmp locations. (note: User bind
# control is only allowed if the host also supports PR_SET_NO_NEW_PRIVS)
<% if scope.lookupvar('::singularity::user_bind_control') -%>
user bind control = yes
<% else -%>
user bind control = no
<% end -%>

# ENABLE OVERLAY: [yes/no/try]
# DEFAULT: try
# Enabling this option will make it possible to specify bind paths to locations
# that do not currently exist within the container.  If 'try' is chosen,
# overlayfs will be tried but if it is unavailable it will be silently ignored.
<% enable_overlay = scope.lookupvar('::singularity::enable_overlay') -%>
<% if !! enable_overlay == enable_overlay -%>
<% if enable_overlay -%>
enable overlay = yes
<% else -%>
enable overlay = no
<% end -%>
<% else -%>
enable overlay = <%= enable_overlay %>
<% end -%>

# ENABLE UNDERLAY: [yes/no]
# DEFAULT: yes
# Enabling this option will make it possible to specify bind paths to locations
# that do not currently exist within the container even if overlay is not
# working.  If overlay is available, it will be tried first.
<% if scope.lookupvar('::singularity::enable_underlay') -%>
enable underlay = yes
<% else -%>
enable underlay = no
<% end -%>

# MOUNT SLAVE: [BOOL]
# DEFAULT: yes
# Should we automatically propagate file-system changes from the host?
# This should be set to 'yes' when autofs mounts in the system should
# show up in the container.
<% if scope.lookupvar('::singularity::mount_slave') -%>
mount slave = yes
<% else -%>
mount slave = no
<% end -%>

# SESSIONDIR MAXSIZE: [STRING]
# DEFAULT: 16
# This specifies how large the default sessiondir should be (in MB) and it will
# only affect users who use the "--contain" options and don't also specify a
# location to do default read/writes to (e.g. "--workdir" or "--home").
sessiondir max size = <%= scope.lookupvar('::singularity::sessiondir_max_size') %>

# LIMIT CONTAINER OWNERS: [STRING]
# DEFAULT: NULL
# Only allow containers to be used that are owned by a given user. If this
# configuration is undefined (commented or set to NULL), all containers are
# allowed to be used. This feature only applies when Singularity is running in
# SUID mode and the user is non-root.
#limit container owners = gmk, singularity, nobody
<% limit_container_owners = scope.lookupvar('::singularity::limit_container_owners') -%>
<% if limit_container_owners -%>
limit container owners = <%= limit_container_owners.join(', ') %>
<% end -%>

# LIMIT CONTAINER GROUPS: [STRING]
# DEFAULT: NULL
# Only allow containers to be used that are owned by a given group. If this
# configuration is undefined (commented or set to NULL), all containers are
# allowed to be used. This feature only applies when Singularity is running in
# SUID mode and the user is non-root.
#limit container groups = group1, singularity, nobody
<% limit_container_groups = scope.lookupvar('::singularity::limit_container_groups') -%>
<% if limit_container_groups -%>
limit container groups = <%= limit_container_groups.join(', ') %>
<% end -%>

# LIMIT CONTAINER PATHS: [STRING]
# DEFAULT: NULL
# Only allow containers to be used that are located within an allowed path
# prefix. If this configuration is undefined (commented or set to NULL),
# containers will be allowed to run from anywhere on the file system. This
# feature only applies when Singularity is running in SUID mode and the user is
# non-root.
#limit container paths = /scratch, /tmp, /global
<% limit_container_paths = scope.lookupvar('::singularity::limit_container_paths') -%>
<% if limit_container_paths -%>
limit container paths = <%= limit_container_paths.join(', ') %>
<% end -%>

# ALLOW CONTAINER ${TYPE}: [BOOL]
# DEFAULT: yes
# This feature limits what kind of containers that Singularity will allow
# users to use (note this does not apply for root).
<% if scope.lookupvar('::singularity::allow_container_squashfs') -%>
allow container squashfs = yes
<% else -%>
allow container squashfs = no
<% end -%>
<% if scope.lookupvar('::singularity::allow_container_extfs') -%>
allow container extfs = yes
<% else -%>
allow container extfs = no
<% end -%>
<% if scope.lookupvar('::singularity::allow_container_dir') -%>
allow container dir = yes
<% else -%>
allow container dir = no
<% end -%>

# AUTOFS BUG PATH: [STRING]
# DEFAULT: Undefined
# Define list of autofs directories which produces "Too many levels of symbolink links"
# errors when accessed from container (typically bind mounts)
#autofs bug path = /nfs
#autofs bug path = /cifs-share
<% autofs_bug_path = scope.lookupvar('::singularity::autofs_bug_path') -%>
<% autofs_bug_path.each do |abp| -%>
autofs bug path = <%= abp %>
<% end -%>

# ALWAYS USE NV ${TYPE}: [BOOL]
# DEFAULT: no
# This feature allows an administrator to determine that every action command
# should be executed implicitely with the --nv option (useful for GPU only 
# environments). 
<% if scope.lookupvar('::singularity::always_use_nv') -%>
always use nv = yes
<% else -%>
always use nv = no
<% end -%>

# ROOT DEFAULT CAPABILITIES: [full/file/no]
# DEFAULT: no
# Define default root capability set kept during runtime
# - full: keep all capabilities (same as --keep-privs)
# - file: keep capabilities configured in ${prefix}/etc/singularity/capabilities/user.root
# - no: no capabilities (same as --no-privs)
root default capabilities = <%= scope.lookupvar('::singularity::root_default_capabilities') %>

# MEMORY FS TYPE: [tmpfs/ramfs]
# DEFAULT: tmpfs
# This feature allow to choose temporary filesystem type used by Singularity.
# Cray CLE 5 and 6 up to CLE 6.0.UP05 there is an issue (kernel panic) when Singularity
# use tmpfs, so on affected version it's recommended to set this value to ramfs to avoid
# kernel panic
memory fs type = <%= scope.lookupvar('::singularity::memory_fs_type') %>

# CNI CONFIGURATION PATH: [STRING]
# DEFAULT: Undefined
# Defines path from where CNI configuration files are stored
<% cni_config_path = scope.lookupvar('::singularity::cni_config_path') -%>
<% if cni_config_path -%>
cni configuration path = <%= cni_config_path %>
<% else -%>
#cni configuration path =
<% end -%>

# CNI PLUGIN PATH: [STRING]
# DEFAULT: Undefined
# Defines path from where CNI executable plugins are stored
<% cni_plugin_path = scope.lookupvar('::singularity::cni_plugin_path') -%>
<% if cni_plugin_path -%>
cni plugin path = <%= cni_plugin_path %>
<% else -%>
#cni plugin path =
<% end -%>

# MKSQUASHFS PATH: [STRING]
# DEFAULT: Undefined
# This allows the administrator to specify the location for mksquashfs if it is not
# installed in a standard system location
<% mksquashfs_path = scope.lookupvar('::singularity::mksquashfs_path') -%>
<% if mksquashfs_path -%>
mksquashfs path = <%= mksquashfs_path %>
<% else -%>
# mksquashfs path =
<% end -%>

# SHARED LOOP DEVICES: [BOOL]
# DEFAULT: no
# Allow to share same images associated with loop devices to minimize loop
# usage and optimize kernel cache (useful for MPI)
<% if scope.lookupvar('::singularity::shared_loop_devs') -%>
shared loop devices = yes
<% else -%>
shared loop devices = no
<% end -%>
